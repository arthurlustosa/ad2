---
title: "Lab2 - Regressão Linear"
autor: "Arthur Lustosa"
output: 
  html_document:
    toc : true
    toc_float: true
    
---

```{r setup, include=FALSE}
library(dplyr)
library(reshape2)
library(GGally)
library(ggplot2)
library(corrplot)
library(caret)
```


## Lendo os dados

```{r}
graduados.train <- read.csv("dados/graduados_treino.csv")
graduados.test <- read.csv("dados/graduados_teste.csv")
```

```{r}
colnames(graduados.train) <- c("matricula", "ano_evasao", "periodo_evasao", "cod_disciplina", "disciplina", "creditos", "media")
```

## Conhecendo os dados
Os dados usados são referentes ao histórico de alunos do curso de computação da UFCG. A tarefa é, utilizando regressão linear, explicar o desempenho acadêmico.

O dataset inicial possui 15751 observações com 7 variáveis. No processo de leitura algumas alterações tiveram de ser feitas, encontramos muitos NaNs e tivemos que removelos para não influenciar nas análises que serão feitas. Depois calculamos os CRAs (Coeficiente de Rendimento Acadêmico) dos alunos. 
```{r warning=F, message=F}
#ordenando os dados pela matrícula
graduados <- graduados.train %>%
  arrange(matricula)

#filtrando dados e removendo os NaNs
graduados.clean <- graduados %>%
  filter(!is.na(media))

#calculando CRA dos alunos e salvando numa coluna
graduados.cra <- graduados.clean %>%
  group_by(matricula) %>%
  mutate(cra.contrb = media*creditos) %>%
  summarise(cra = sum(cra.contrb)/sum(creditos))

#utilizando a função dcast para deixar o dataset na forma ideal para a análise
graduados.model.input <- graduados.clean %>%
  group_by(matricula, disciplina) %>%
  filter(media == max(media))%>%
  ungroup() %>%
  select(matricula, disciplina, media) %>%
  mutate(disciplina = as.factor(gsub(" ", ".", disciplina))) %>%
  dcast(matricula ~disciplina, mean) %>%
  merge(graduados.cra)
```

## Períodos Iniciais

```{r warning=F, message=F}
#selecionando cra e disciplinas do primeiro e segundo período
p1.p2 <- graduados.model.input %>%
  select(Laboratório.de.Programação.I, Programação.I, Introdução.à.Computação, Cálculo.Diferencial.e.Integral.I, Álgebra.Vetorial.e.Geometria.Analítica, Leitura.e.Produção.de.Textos, Cálculo.Diferencial.e.Integral.II, Matemática.Discreta, Programação.II, Teoria.dos.Grafos, Fundamentos.de.Física.Clássica, Laboratório.de.Programação.II, cra)

#renomeando colunas
colnames(p1.p2) <- c("C1", "Vetorial", "LPT", "P1", "IC", "LP1","C2", "Discreta", "P2", "Grafos", "Física", "LP2", "CRA")

#removendo NaNs
p1.p2 <- na.omit(p1.p2)

#calculando modelo linear
lm.p1p2 <-lm(CRA ~ ., p1.p2)

summary(lm.p1p2)
```

O que fazer:
1. Separe os dados em treino e teste (por exemplo 90% para treino 10% para teste).
2. Usando todas as variáveis disponíveis (disciplinas do primeiro e segundo período), use validação cruzada (nos dados de treino) para tunar um modelo de regressão Ridge.
3. Mesmo que item acima mas usando um modelo de regressão Lasso.
4. Compare os dois modelos nos dados de teste em termos de RMSE.
5. Quais as variáveis mais importantes segundo o modelo de regressão Lasso? Alguma variável foi descartada? Quais?
6. Re-treine o melhor modelo (dessa vez nos dados de treino sem validação cruzada) e reporte o RMSE no teste.
7. Use o modelo treinado em 6 e aplique nos dados de teste que vamos disponibilizar.
8. Crie novos atributos a partir dos existentes para tentar melhorar o seu modelo.


Usamos a biblioteca caret para particionar os dados e montarmos nosso conjunto de teste.
```{r}
#separando os dados em treino e teste
in.train <- createDataPartition(y=p1.p2$CRA, p = 0.90)

```


Criando modelo de regressão do tipo Ridge que utiliza todas as variáveis.
```{r}
p1.p2.train <- p1.p2[in.train[[1]],]
p1.p2.test <- p1.p2[-in.train[[1]],]


model.rigde.p1.p2.train <- train(CRA ~ . #funcao
                        , p1.p2.train #dados
                        , method = "ridge") #metodo

model.rigde.p1.p2.train 

```
```{r}
p1.p2.pred <- predict(model.rigde.p1.p2.train, p1.p2.test)
#RMSE
sqrt(mean((p1.p2.pred-p1.p2.test$CRA)^2))
```

Criando modelo de regressão do tipo Lasso que utiliza todas as variáveis.
```{r}
model.lasso.p1.p2.train <- train(CRA ~. #funcao
                        , p1.p2.train #dados
                        , method = "lasso") #metodo

model.lasso.p1.p2.train
```




```{r}
#tutorial caret
library(caret)

#particionando dados para treino 75%
in.train <- createDataPartition(y=dataset$variavelRespota, p = 0.75)

#selecionando linhas para treomp
mtcars.train <- mtcars[in.train[[1]],]
mtcars.test <- mtcars[in.train[[1]],]

#treinando o modelo
model.mtcars_lm <- train(mpg ~ wt #funcao
                        , mtcars.train #dados
                        , method = "lm") #metodo

#fazendo predicao
mtcars.pred <- predict(model.mtcars_lm, mtcars.test)

#calculando RMSE 
sqrt(mean(mtcarts.pred-mtcars.test$mpg)^2) #significa o quanto nosso modelo vai predizer, de acordo com o contexto do problema.

#exemplo com regularizacao, a diferença entre a regressao e a regularizacao, na regressao normal vamos minimizar o erro e na regularização vamos minimizar o erro e o número de variáveis. 
#diferenca entre ridge e lasso é a distância. Ridge: L1 e Lasso L2

#importancia das variaveis
roc_imp2 <- varImp(lasso, scale=F)
plot(roc_imp2)


```

