---
title: "Predição - Utilizando Ridge e Lasso"
autor: "Arthur Lustosa"
output: 
  html_document:
    toc : true
    toc_float: true
    
---

#Predição
##Utilizando Ridge e Lasso

Nessa análise construíremos modelos preditivos de regressão para predição do CRA (Coeficiente de Rendimento Acadêmico) baseado nas notas obtidas nas disciplinas do primeiro e do segundo período dos alunos de Ciência da Computação - UFCG.

Bibliotecas utilizadas
```{r setup, include=FALSE}
library(dplyr)
library(reshape2)
library(ggplot2)
library(corrplot)
library(caret)
```


##Lendo os dados
Recebemos os dataset já separados em treino e test.
```{r}
graduados.train <- read.csv("dados/graduados_treino.csv")
graduados.test <- read.csv("dados/graduados_teste.csv") #validacao

test <- read.csv("dados/test.csv")
```

##Conhecendo os dados

Um prepocessamento nos dados foi necessário antes de iniciarmos nossa análise. Foi preciso calcular o CRA dos alunos e selecionar apenas as disciplinas referentes ao primeiro e segundo perído do curso. Após o processamento nossos dados ficaram no seguinte formato:

*matricula
*ano_evasao
*periodo_evasao
*cod_disciplina
*disciplina
*creditos
*media

```{r, echo=F}
colnames(graduados.train) <- c("matricula", "ano_evasao", "periodo_evasao", "cod_disciplina", "disciplina", "creditos", "media")
colnames(graduados.test) <- c("matricula", "ano_evasao", "periodo_evasao", "cod_disciplina", "disciplina", "creditos", "media")
```


```{r warning=F, message=F, echo=F}

# DADOS TREINO

#ordenando os dados pela matrícula
graduados.train <- graduados.train %>%
  arrange(matricula)

#filtrando dados e removendo os NaNs
graduados.clean <- graduados.train %>%
  filter(!is.na(media))

#calculando CRA dos alunos e salvando numa coluna
graduados.cra <- graduados.clean %>%
  group_by(matricula) %>%
  mutate(cra.contrb = media*creditos) %>%
  summarise(cra = sum(cra.contrb)/sum(creditos))

#utilizando a função dcast para deixar o dataset na forma ideal para a análise
graduados.model.input <- graduados.clean %>%
  group_by(matricula, disciplina) %>%
  filter(media == max(media))%>%
  ungroup() %>%
  select(matricula, disciplina, media) %>%
  mutate(disciplina = as.factor(gsub(" ", ".", disciplina))) %>%
  dcast(matricula ~disciplina, mean) %>%
  merge(graduados.cra)

#selecionando cra e disciplinas do primeiro e segundo período
p1.p2.train <- graduados.model.input %>%
  select(Laboratório.de.Programação.I, Programação.I, Introdução.à.Computação, Cálculo.Diferencial.e.Integral.I, Álgebra.Vetorial.e.Geometria.Analítica, Leitura.e.Produção.de.Textos, Cálculo.Diferencial.e.Integral.II, Matemática.Discreta, Programação.II, Teoria.dos.Grafos, Fundamentos.de.Física.Clássica, Laboratório.de.Programação.II, cra)

#renomeando colunas
colnames(p1.p2.train) <- c("C1", "Vetorial", "LPT", "P1", "IC", "LP1","C2", "Discreta", "P2", "Grafos", "Física", "LP2", "CRA")


# DADOS VALIDACAO

#ordenando os dados pela matrícula
graduados.test <- graduados.test %>%
  arrange(matricula)

#filtrando dados e removendo os NaNs
graduados.clean <- graduados.test %>%
  filter(!is.na(media))

#calculando CRA dos alunos e salvando numa coluna
graduados.cra <- graduados.clean %>%
  group_by(matricula) %>%
  mutate(cra.contrb = media*creditos) %>%
  summarise(cra = sum(cra.contrb)/sum(creditos))

#utilizando a função dcast para deixar o dataset na forma ideal para a análise
graduados.model.input <- graduados.clean %>%
  group_by(matricula, disciplina) %>%
  filter(media == max(media))%>%
  ungroup() %>%
  select(matricula, disciplina, media) %>%
  mutate(disciplina = as.factor(gsub(" ", ".", disciplina))) %>%
  dcast(matricula ~disciplina, mean) %>%
  merge(graduados.cra)

#selecionando cra e disciplinas do primeiro e segundo período
p1.p2.test <- graduados.model.input %>%
  select(Laboratório.de.Programação.I, Programação.I, Introdução.à.Computação, Cálculo.Diferencial.e.Integral.I, Álgebra.Vetorial.e.Geometria.Analítica, Leitura.e.Produção.de.Textos, Cálculo.Diferencial.e.Integral.II, Matemática.Discreta, Programação.II, Teoria.dos.Grafos, Fundamentos.de.Física.Clássica, Laboratório.de.Programação.II, cra)

#renomeando colunas
colnames(p1.p2.test) <- c("C1", "Vetorial", "LPT", "P1", "IC", "LP1","C2", "Discreta", "P2", "Grafos", "Física", "LP2", "CRA")



#substituindo NaN pelo CRA
for (i in 1:nrow(p1.p2.train)){
  for (j in 1:ncol(p1.p2.train)){
    if(is.na(p1.p2.train[i,j])){
      p1.p2.train[i,j] = p1.p2.train$CRA[i]

    }
    if(is.na(p1.p2.test[i,j])){
      p1.p2.test[i, j] = p1.p2.test$CRA[i]
    }
  }
}

```


Após processarmos os dados tivemos que fazer mais algumas alterações para os dados ficassem no formato necessário para criar os modelos. Os atributos dos dados ficaram sendo as disciplinas e a última coluna como sendo a variável alvo. As linhas são as notas dos alunos, a matrícula foi removida devido a confidencialidade dos dados.

```{r}
head(p1.p2.train)
```
Antes de iniciarmos nossa análise vamos observar a correlação das variáveis em relação a variável alvo.

```{r fig.width=12, fig.height=10, warning=F, message=F}
#calculando matriz de correlação
correlationMatrix <- cor(p1.p2.train)

#utlizamos a bibliota corrplot para montar o gráfico com as correlações
corrplot(correlationMatrix, method="circle", type="lower", order="hclust", addCoef.col = "black")
```
Vemos que a disciplina de cálculo 2, LPT e matemática discreta são as disciplinas que possuem correlação mais alta com o CRA do aluno. 

Vamos agora para nossa análise preditiva, para isso vamos seguir os passos descritos abaixo:

*1.* Usando todas as variáveis disponíveis (disciplinas do primeiro e segundo período), use validação cruzada (nos dados de treino) para tunar um modelo de regressão Ridge.
*2.* Mesmo que item acima mas usando um modelo de regressão Lasso.
*3.* Compare os dois modelos nos dados de teste em termos de RMSE.
*4.* Quais as variáveis mais importantes segundo o modelo de regressão Lasso? Alguma variável foi descartada? Quais?
*5.* Re-treine o melhor modelo (dessa vez nos dados de treino sem validação cruzada) e reporte o RMSE no teste.
*6.* Use o modelo treinado em 6 e aplique nos dados de teste que vamos disponibilizar.
*7.* Crie novos atributos a partir dos existentes para tentar melhorar o seu modelo.


##2 Ridge
O modelo inicial utiliza o Ridge. A Ridge Regression é um método de regularização do modelo que tem como principal objetivo suavizar atributos que sejam relacionados uns aos outros e que aumentam o ruído no modelo (A.K.A multicolinearidade). Para aplicarmos o Ridge utilizamos a biblioteca caret. 

```{r fig.width=12, fig.height=10, warning=F, message=F}
#Modelo Ridge
set.seed(825)

ctrl <- trainControl(method = "repeatedcv", repeats = 5, number = 10)
lambda.grid <- expand.grid(lambda = seq(0, 2, by=0.05))

ridge <- train(CRA ~ . ,data = p1.p2.train,
                        method = "ridge",
                        tuneGrid = lambda.grid,
                        trControl = ctrl,
                        metric = 'RMSE',
                        preProcess=c('scale', 'center'))
plot(ridge)
```

A função train utilizou um vetor com 100 possíveis valores para lambda e achou o valor ótimo (RMSE mais baixo).

```{r}
ridge
```

Depois de criado o modelo iremos agora gerar a previsão.

```{r}
ridge_prediction <- predict(ridge, p1.p2.train)

ridge_prediction <- data.frame(pred = ridge_prediction, obs = p1.p2.train$CRA)
round(defaultSummary(ridge_prediction), digits = 3)
```

##3 Lasso
Iremos agora criar um modelo utilizando o Lasso. O Lasso é uma técnica que, além de controlar o overfitting, aplica a seleção de variáveis que melhor explicam a variável resposta. Para criar esse modelo usaremos a biblioteca caret.
```{r fig.width=12, fig.height=10, warning=F, message=F}
#Modelo Lasso
set.seed(825)
lasso <- train(CRA ~ . ,data = p1.p2.train,
                        method = "lasso",
                        tuneLength = 10,
                        metric = 'RMSE',
                        preProcess=c('scale', 'center'))
plot(lasso)
```
A função train tentou 10 valores para fraction e achou o valor ótimo (RMSE mais baixo).

```{r}
lasso
```

Depois de criado o modelo iremos agora gerar a previsão.

```{r}
lasso_prediction <- predict(lasso, p1.p2.train)

lasso_prediction <- data.frame(pred = lasso_prediction, obs = p1.p2.train$CRA)
round(defaultSummary(lasso_prediction), digits = 3)

```


##4 Comparando os modelos

```{r fig.width=12, fig.height=10, warning=F, message=F}
compare <- ridge_prediction
compare$model <- "RIDGE"

lasso_prediction$model <- "LASSO"

compare <- rbind(compare, lasso_prediction)

ggplot(compare, aes(x = pred, y = obs)) + 
  geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + 
  facet_grid(. ~ model) + 
  geom_abline() +
  ggtitle("Observado x Previsão (validação)")

```

```{r}
round(defaultSummary(ridge_prediction), digits = 3)
round(defaultSummary(lasso_prediction), digits = 3)
```
O melhor modelo será aquele que possuir o RMSE mais baixo. Como podemos ver, ambos os modelos produziram um RMSE próximo, ou seja, não temos uma diferença tão significativa entre os modelos. Entre o Lasso e o Ridge ficamos com o Ridge que ficou com RMSE ~0.459


##5 Importância das Variáveis

```{r}
plot(varImp(ridge, scale = FALSE))
plot(varImp(lasso, scale = FALSE))

predict.enet(lasso$finalModel, type='coefficients', s=lasso$bestTune$fraction, mode='fraction')
```

Acima temos o gráfico com a importância das variáveis para cada modelo, primeiro para o ridge depois para o lasso. Concluímos que as variáveis possuem a mesma importância para cada modelo.

```{r fig.width=12, fig.height=10, warning=F, message=F}
ggplot(data = p1.p2.train, aes(x = CRA, y = C2)) +
  geom_point()
```
Vamos observar um pouco mais a fundo a relação entre C2 e o CRA, já que os nossos modelos apontaram essa variável como sendo a mais importante. Vamos que C2 e CRA tem um comportamento bem linear, temos alguns outliers, mas podemos concluir que quanto mais alta a nota em C2 consequentemente mais alto o CRA.


##6 Re-treino Ridge
```{r fig.width=12, fig.height=10, warning=F, message=F}
p1.p2.test <- na.omit(p1.p2.test)
r.ridge <- train(CRA ~ . ,data = p1.p2.test,
                        method = "ridge",
                        tuneGrid = lambda.grid,
                        trControl = ctrl,
                        metric = 'RMSE',
                        preProcess=c('scale', 'center'))
r.ridge 
plot(r.ridge)
```

```{r}
#predicao do re-treino
r.ridge_prediction <- predict(r.ridge, p1.p2.test)

r.ridge_prediction <- data.frame(pred = r.ridge_prediction, obs = p1.p2.test$CRA)
round(defaultSummary(r.ridge_prediction), digits = 3)
```

##7 Treino com dados de teste
```{r}
lasso_prediction <- predict(lasso, test)

lasso_prediction <- data.frame(pred = lasso_prediction, obs = p1.p2.train$CRA)
round(defaultSummary(lasso_prediction), digits = 3)
```


##8 Comparando Modelos com treino e teste

Para termos uma comparação mais robusta, propusemos um modelo de regressão linear. Primeiro rodamos com todas as variáveis, depois só com as mais significativas e tivemos o seguinte resultado.  
```{r}
lm <- train(CRA ~ . ,p1.p2.train, method= "lm", metric="RMSE") 
summary(lm)

lmFit <- train(CRA ~ ., p1.p2.train %>% select(-C1, -LP2), method= "lm", metric="RMSE") 
summary(lmFit)

lmFit_prediction <- predict(lmFit, p1.p2.train)

lmFit_prediction <- data.frame(pred = lmFit_prediction, obs = p1.p2.train$CRA)
round(defaultSummary(lmFit_prediction), digits = 3)

```
Nosso modelo linear apresentou um RMSE parecido com o dos modelos já expostos, porém com um alto R-squared. No gráfico abaixo podemos analisar nossa comparação.
```{r}

linear_rmse <- round(defaultSummary(lmFit_prediction), digits = 3)[1]
ridge_rmse <- round(defaultSummary(ridge_prediction), digits = 3)[1]
lasso_rmse <- round(defaultSummary(lasso_prediction), digits = 3)[1]
toPlot <- data.frame(RMSE = c(linear_rmse, ridge_rmse, lasso_rmse), 
                     Modelo = c("Linear Regression", "Ridge", "Lasso"))


ggplot(toPlot, aes(x=reorder(Modelo, -RMSE), y=RMSE)) + 
  geom_bar(stat="identity") + 
  labs(x='Modelo', y='RMSE') +
   theme(axis.text.x = element_text(angle = 45, hjust = 1), panel.background=element_blank()) +
  coord_flip() + 
  geom_text(aes(label = RMSE))
```

O melhor modelo será aquele que possuir o RMSE mais baixo. Utilizando essa métrica o melhor modelo gerado foi o utilizando Ridge com o cross validation seguido pelo modelo utilizando regressão linear e depois o Lasso. Vale salientar que a diferença entre os modelos é baixissíma.

###Treino vs Validação

```{r}
# RIDGE
ridge.validacao <- train(CRA ~ . ,data = p1.p2.test,
                        method = "ridge",
                        tuneGrid = lambda.grid,
                        trControl = ctrl,
                        metric = 'RMSE',
                        preProcess=c('scale', 'center'))

# LASSO
lasso.validacao <- train(CRA ~ . ,data = p1.p2.test,
                        method = "lasso",
                        tuneLength = 10,
                        metric = 'RMSE',
                        preProcess=c('scale', 'center'))

# LM
lm.validacao <- train(CRA ~ ., p1.p2.test %>% select(-C1, -LP2), method= "lm", metric="RMSE") 

ridge_prediction_v <- predict(ridge.validacao, p1.p2.test)
ridge_prediction_v <- data.frame(pred = ridge_prediction_v, obs = p1.p2.test$CRA)

lasso_prediction_v <- predict(lasso.validacao, p1.p2.test)
lasso_prediction_v <- data.frame(pred = lasso_prediction_v, obs = p1.p2.test$CRA)

lm_prediction_v <- predict(lm.validacao, p1.p2.test)
lm_prediction_v <- data.frame(pred = lm_prediction_v, obs = p1.p2.test$CRA)


linear_rmse_v <- round(defaultSummary(lm_prediction_v), digits = 3)[1]
ridge_rmse_v <- round(defaultSummary(ridge_prediction_v), digits = 3)[1]
lasso_rmse_v <- round(defaultSummary(lasso_prediction_v), digits = 3)[1]

```


```{r}

toPlot3 <- data.frame(RMSE = c(linear_rmse, linear_rmse_v, ridge_rmse, ridge_rmse_v, lasso_rmse, lasso_rmse_v),
                        tipo = c("treino", "validacao", "treino", "validacao", "treino", "validacao"),
                        modelo = c("LM","LM","RIDGE", "RIDGE","LASSO", "LASSO"))

ggplot(data=toPlot3, aes(x = modelo, y = RMSE, fill = tipo)) +
 geom_bar(stat="identity", position=position_dodge()) +
 theme_classic() +
 labs(title = "Comparando os modelos") +
 theme(axis.ticks = element_blank())
```


##9 Melhorando o modelo

##10 Conclusões
